#!/usr/bin/env ruby

require 'faraday_middleware'
require 'typhoeus/adapters/faraday'
require 'multi_json'
require 'ruby-progressbar'
require 'terminal-table'
require 'logger'
require 'csv'

require 'dotenv'
Dotenv.load

logger       = Logger.new(File.expand_path('../../log/development.log', __FILE__))
requests_log = Logger.new(File.expand_path('../../log/requests.log', __FILE__))

connection = Faraday.new(url: ENV.fetch('API_ENDPOINT')) do |c|
  c.response(:logger, requests_log)
  c.adapter(:typhoeus)
end

connection.headers['Content-Type']  = 'application/json'
connection.headers['Accept']        = 'application/json'
connection.headers['Authorization'] = "Bearer %s" % [ENV.fetch('PERSONAL_TOKEN')]

query_params = {
  :start_at => "2014-06-26T14:29:32Z",
  :end_at   => "2014-09-26T14:29:45Z",
  :property_id => '9c7365e8-0877-1031-a8b0-22000a9f01ba',
  :property_date => 'first_ever'
}

metric_id  = ENV.fetch('METRIC_ID')
metric_url = "/query/metrics/%s/by-segment" % [metric_id]

logger.info(metric_id) { "Starting the Metrics Over Time query to %s" % [metric_url] }

request = connection.post(metric_url, MultiJson.dump(query_params))

case(request.status)
when 202
  status_url = request.headers.fetch('location')

  query_params = {
    :limit => ENV.fetch('RESULTS_LIMIT', 100)
  }

  status_request = connection.get(status_url, query_params)

  case(status_request.status)
  when 200
    logger.info(metric_id) { "Polling the status from %s" % [status_url] }
    progress_bar = ProgressBar.create(title: 'Results status', starting_at: 0, total: 1.0)

    # Poll the status until it's completed
    next_request = loop do
      poll_status_request  = connection.get(status_url, query_params)
      poll_status_response = MultiJson.load(poll_status_request.body)

      poll_status = poll_status_response.fetch('data', [])

      #break poll_status_request if poll_status_response['completed'] == true || (poll_status_response.has_key?('error') && !poll_status_response['error'].nil?)
      #break poll_status_request if poll_status['progress'] < 1.0
      break poll_status_request if poll_status_request.status == 303
      progress_bar.progress = poll_status['progress']
      logger.info(metric_id) { "Progress: %s" % [poll_status['progress']] }
    end
    progress_bar.finish

    case(next_request.status)
    when 303
      results_url = next_request.headers.fetch('location')

      logger.info(metric_id) { "Retrieving results from %s" % [results_url] }

      results_request = connection.get(results_url, query_params)

      case(results_request.status)
      when 200
        data = []

        results_response = MultiJson.load(results_request.body)

        data.concat(results_response.fetch('data', []))

        links     = results_response.fetch('links', [])
        next_link = links.select { |r| r['rel'] == 'next' }.first

        if next_link
          loop do
            logger.info(metric_id) { "Retrieving paginated set %s" % [next_link['href']] }

            results_request  = connection.get(next_link['href'])
            results_response = MultiJson.load(results_request.body)

            links     = results_response.fetch('links', [])
            next_link = links.select { |r| r['rel'] == 'next' }.first

            data.concat(results_response.fetch('data', []))
            break if next_link.nil?
          end
        end

        data_display = ->(record) do
          [record['property_value'][0..45], record['people_count'], record['value']]
        end

        rows = data.map { |r| data_display.call(r) }
        headings = ['Property Value', 'Num People', 'Value']

        # Output to the console
        table = Terminal::Table.new(title: 'Query Results', headings: headings, rows: rows)
        puts table.to_s

        # Write to a final JSON file
        final_response_body = {
          :total    => results_response.fetch('total', 0),
          :metadata => results_response.fetch('metadata', {}),
          :data     => data
        }

        logger.info(metric_id) { 'Writing to cache/results.json cache' }
        File.open(File.expand_path('../../cache/results.json', __FILE__), 'w+') do |f|
          f.write(MultiJson.dump(final_response_body))
        end

        logger.info(metric_id) { 'Writing to cache/results.csv cache' }
        CSV.open(File.expand_path('../../cache/results.csv', __FILE__), 'w+') do |csv|
          csv << headings
          rows.each { |r| csv << r }
        end
      else
        logger.error(metric_id) { "[Results Request] There was an error (%s)\n%s" % [results_request.status, results_request.inspect] }
      end
    else
      logger.error(metric_id) { "[Status Ping Request] There was an error (%s)\n%s" % [next_request.status, next_request.inspect] }
    end
  else
    logger.error(metric_id) { "[Initial Status Request] There was an error (%s)\n%s" % [status_request.status, status_request.inspect] }
  end
else
  logger.error(metric_id) { "[Initial Request] There was an error (%s)\n%s" % [request.status, request.inspect] }
end

